{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_brands = set(['dsc','stylus', 'elph', 'powershot', 'iphone', 'enxun', 'fugi', 'electric', 'howell', 'kitty', 'blue', 'figi', 'go', 'sonydigital', 'cyber', 'fujifilm', 'digital blue', 'bell howell', 'bell+howell', 'hello kitty', 'vistaquest', 'blackmagic', 'superheadz', 'hasselblad', 'hikivision', 'fuijifilm', 'panasonic', 'fugi film', 'fiji film', 'hikvision', 'polaroid', 'insignia', 'keychain', 'yourdeal', 'lowrance', 'logitech', 'fijifilm', 'bushnell', 'fujufilm', 'fugifilm', 'sylvania', 'olympul', 'lowepro', 'toshiba', 'olympus', 'samsung', 'finepix', 'fuifilm', 'samyang', 'aquapix', 'vivitar', 'neopine', 'minolta', 'easypix', 'sandisk', 'vivicam', 'philips', 'coleman', 'yashica', 'coolpix', 'emerson', 'sealife', 'crayola', 'intova', 'tamron', 'cannon', 'garmin', 'pentax', 'barbie', 'konica', 'mustek', 'aiptek', 'keedox', 'contax', 'konika', 'go pro', 'olymus', 'philip', 'wopson', 'pextax', 'wespro', 'disney', 'rollei', 'sakar', 'lytro', 'apple', 'lexar', 'kodak', 'vibe ', 'drift', 'vtech', 'vizio', 'kinon', 'haier', 'epson', 'gopro', 'croco', 'minox', 'nokia', 'dahua', 'sanyo', 'intel', 'kodax', 'ricoh', 'argus', 'lumix', 'nikon', 'absee', 'nicon', 'bmpcc', 'canon', 'casio', 'cobra', 'leica', 'sigma', 'sony', 'fuji', 'b h ', 'lego', 'benq', 'asus', 'pov', 'jvc', 'b+w', 'ion', 'lg ', 'dji', 'tvc', 'eos', 'ge ', 'vpc', 'dxg', 'svp', 'hp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import math\n",
    "\n",
    "sentences = []\n",
    "\n",
    "webs = [f for f in listdir('/home/sunji/EM_sigmod/2013_camera_specs')]\n",
    "for w in webs:\n",
    "    items = [f for f in listdir('/home/sunji/EM_sigmod/2013_camera_specs/'+w)]\n",
    "    for it in items:\n",
    "        with open('/home/sunji/EM_sigmod/2013_camera_specs/'+w+'/'+it, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            sentence = ''\n",
    "            for k, v in data.items():\n",
    "                sentence += str(k)\n",
    "                sentence += ' '\n",
    "                if type(v) == list:\n",
    "                    for vv in v:\n",
    "                        sentence += str(vv)\n",
    "                        sentence += ' '\n",
    "                else:\n",
    "                    sentence += str(v)\n",
    "                    sentence += ' '\n",
    "            sentences.append(sentence)\n",
    "\n",
    "total_words_num = 0\n",
    "            \n",
    "word_freqs = {}\n",
    "for s in sentences:\n",
    "    for ss in s.split(' '):\n",
    "        total_words_num += 1\n",
    "        if ss.lower() in word_freqs:\n",
    "            word_freqs[ss.lower()] += 1\n",
    "        else:\n",
    "            word_freqs[ss.lower()] = 1\n",
    "for k in word_freqs.keys():\n",
    "    word_freqs[k] /= float(total_words_num)\n",
    "\n",
    "word_df = {}\n",
    "for s in sentences:\n",
    "    for ss in set(s.lower().split(' ')):\n",
    "        if ss in word_df:\n",
    "            word_df[ss] += 1\n",
    "        else:\n",
    "            word_df[ss] = 1\n",
    "for k in word_df.keys():\n",
    "    word_df[k] = math.log(len(sentences) / float(word_df[k]))\n",
    "    \n",
    "word_tfidf = {}\n",
    "for k in word_df.keys():\n",
    "    word_tfidf[k] = word_freqs[k] * word_df[k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(word_tfidf.items(), key=lambda x:x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "structured_data = pd.read_csv('quickstart_package/extracted_dataset_key.csv')\n",
    "structured_data = structured_data.set_index('spec_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs = pd.read_csv('/home/sunji/EM_sigmod/quickstart_package/candidate_pairs_quickstart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(structured_data[pd.isnull(structured_data['type'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "products_labeled = pd.read_csv('/home/sunji/EM_sigmod/sigmod_large_labelled_dataset.csv')\n",
    "# products_labeled['type'] = products_labeled['type'].fillna('')\n",
    "# products_labeled['camera_title_overlap_freq'] = products_labeled['camera_title_overlap_freq'].fillna('')\n",
    "# products_labeled['camera_title_unmatch_freq'] = products_labeled['camera_title_unmatch_freq'].fillna('')\n",
    "def training_bloking(row):\n",
    "    llll = structured_data.loc[row['left_spec_id']]['blocking_key']\n",
    "    rrrr = structured_data.loc[row['right_spec_id']]['blocking_key']\n",
    "    return llll == rrrr\n",
    "\n",
    "products_labeled = products_labeled[products_labeled.swifter.apply(lambda x: training_bloking(x), axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import editdistance\n",
    "\n",
    "def feature_extraction(pairs_df):\n",
    "    stopped_words = set(['digital camera', 'camera']) | all_brands\n",
    "\n",
    "    camera_type_jaccard_dis = []\n",
    "    camera_type_numeric_jaccard_dis = []\n",
    "    camera_title_jaccard_dis = []\n",
    "    camera_type_overlap_dis = []\n",
    "    camera_type_numeric_overlap_dis = []\n",
    "    camera_title_overlap_dis = []\n",
    "    camera_title_overlap_freq = []\n",
    "    camera_title_unmatch_freq = []\n",
    "    camera_type_edit_dis = []\n",
    "    camera_title_edit_dis = []\n",
    "    camera_title_numeric_jaccard_dis = []\n",
    "    camera_title_numeric_edit_dis = []\n",
    "    \n",
    "    cnt = 0\n",
    "    for _, row in pairs_df.iterrows():\n",
    "    #   camera_brand_dis\n",
    "        if cnt % 100 == 0:\n",
    "            print (cnt)\n",
    "        cnt += 1\n",
    "        llll = structured_data.loc[row['left_spec_id']]\n",
    "        rrrr = structured_data.loc[row['right_spec_id']]\n",
    "\n",
    "        lset = set(str(llll['type']).split(';'))\n",
    "        rset = set(str(rrrr['type']).split(';'))\n",
    "        \n",
    "        max_len = max(len(str(llll['type'])), len(str(rrrr['type'])))\n",
    "        camera_type_edit_dis.append(editdistance.eval(''.join(sorted(lset)), ''.join(sorted(rset))) / float(max_len))\n",
    "\n",
    "        if len(lset) == 0 and len(rset) == 0:\n",
    "            camera_type_jaccard_dis.append(0.0)\n",
    "            camera_type_overlap_dis.append(0.0)\n",
    "        else:\n",
    "            camera_type_jaccard_dis.append(1.0 - len(lset&rset) / float(len(lset|rset)))\n",
    "            camera_type_overlap_dis.append(1.0 - len(lset&rset) / float(max(len(lset), len(rset))))\n",
    "\n",
    "        lset = set(re.findall(r\"\\d+\\.?\\d*\",str(llll['type'])))\n",
    "        rset = set(re.findall(r\"\\d+\\.?\\d*\",str(rrrr['type'])))\n",
    "\n",
    "        if len(lset) == 0 and len(rset) == 0:\n",
    "            camera_type_numeric_jaccard_dis.append(0.0)\n",
    "            camera_type_numeric_overlap_dis.append(0.0)\n",
    "        else:\n",
    "            camera_type_numeric_jaccard_dis.append(1-len(lset&rset) / float(len(lset|rset)))\n",
    "            camera_type_numeric_overlap_dis.append(1.0 - len(lset&rset) / float(max(len(lset), len(rset))))\n",
    "\n",
    "        lnumtitle = re.findall(r\"\\d+\",str(llll['page_title']))\n",
    "        rnumtitle = re.findall(r\"\\d+\",str(rrrr['page_title']))\n",
    "        \n",
    "        lset = set(lnumtitle)\n",
    "        rset = set(rnumtitle)\n",
    "        \n",
    "        if len(lset) == 0 and len(rset) == 0:\n",
    "            camera_title_numeric_jaccard_dis.append(0.0)\n",
    "            camera_title_numeric_edit_dis.append(0.0)\n",
    "        else:\n",
    "            camera_title_numeric_jaccard_dis.append(1.0 - len(lset&rset) / float(len(lset|rset)))\n",
    "            max_len = max(len(lnumtitle), len(rnumtitle))\n",
    "            camera_title_numeric_edit_dis.append(editdistance.eval(lnumtitle, rnumtitle) / float(max_len))\n",
    "        \n",
    "        ltitle = str(llll['page_title']).split(' ')\n",
    "        rtitle = str(rrrr['page_title']).split(' ')\n",
    "        lset = set(ltitle)\n",
    "        rset = set(rtitle)\n",
    "\n",
    "        if len(lset) == 0 and len(rset) == 0:\n",
    "            camera_title_jaccard_dis.append(0.0)\n",
    "            camera_title_overlap_dis.append(0.0)\n",
    "            camera_title_edit_dis.append(0.0)\n",
    "        else:\n",
    "            camera_title_jaccard_dis.append(1.0-len(lset&rset) / float(len(lset|rset)))\n",
    "            camera_title_overlap_dis.append(1.0 - len(lset&rset) / float(max(len(lset), len(rset))))\n",
    "            max_len = max(len(ltitle), len(rtitle))\n",
    "            camera_title_edit_dis.append(editdistance.eval(ltitle, rtitle) / float(max_len))\n",
    "        overlap_freqs = []\n",
    "        for w in lset&rset:\n",
    "            if w in word_tfidf:\n",
    "                overlap_freqs.append(str(word_tfidf[w]))\n",
    "        camera_title_overlap_freq.append(';'.join(overlap_freqs))\n",
    "        unmatch_freqs = []\n",
    "        for w in (lset|rset)-(lset&rset):\n",
    "            if w in word_tfidf:\n",
    "                unmatch_freqs.append(str(word_tfidf[w]))\n",
    "        camera_title_unmatch_freq.append(';'.join(unmatch_freqs))\n",
    "\n",
    "\n",
    "    pairs_df['camera_type_jaccard_dis'] = camera_type_jaccard_dis\n",
    "    pairs_df['camera_type_overlap_dis'] = camera_type_overlap_dis\n",
    "    pairs_df['camera_type_edit_dis'] = camera_type_edit_dis\n",
    "    pairs_df['camera_type_numeric_jaccard_dis'] = camera_type_numeric_jaccard_dis\n",
    "    pairs_df['camera_type_numeric_overlap_dis'] = camera_type_numeric_overlap_dis\n",
    "    pairs_df['camera_title_jaccard_dis'] = camera_title_jaccard_dis\n",
    "    pairs_df['camera_title_overlap_dis'] = camera_title_overlap_dis\n",
    "    pairs_df['camera_title_edit_dis'] = camera_title_edit_dis\n",
    "    pairs_df['camera_title_numeric_jaccard_dis'] = camera_title_numeric_jaccard_dis\n",
    "    pairs_df['camera_title_numeric_edit_dis'] = camera_title_numeric_edit_dis\n",
    "    pairs_df['camera_title_overlap_freq'] = camera_title_overlap_freq\n",
    "    pairs_df['camera_title_unmatch_freq'] = camera_title_unmatch_freq\n",
    "   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_extraction(products_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_labeled.to_csv('products_labeled_with_distance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "products_labeled = pd.read_csv('products_labeled_with_distance.csv')\n",
    "products_labeled['camera_title_overlap_freq'] = products_labeled['camera_title_overlap_freq'].fillna('')\n",
    "products_labeled['camera_title_unmatch_freq'] = products_labeled['camera_title_unmatch_freq'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products_labeled = products_labeled.drop_duplicates(subset=['camera_type_jaccard_dis',\n",
    "       'camera_type_overlap_dis', 'camera_type_edit_dis',\n",
    "       'camera_type_numeric_jaccard_dis', 'camera_type_numeric_overlap_dis',\n",
    "       'camera_title_jaccard_dis', 'camera_title_overlap_dis',\n",
    "       'camera_title_edit_dis', 'camera_title_overlap_freq',\n",
    "       'camera_title_unmatch_freq', 'camera_title_numeric_jaccard_dis', 'camera_title_numeric_edit_dis'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xxxx = products_labeled[products_labeled.duplicated()]\n",
    "xxx = xxxx.sort_values(by=['camera_type_jaccard_dis',\n",
    "       'camera_type_overlap_dis', 'camera_type_edit_dis',\n",
    "       'camera_type_numeric_jaccard_dis', 'camera_type_numeric_overlap_dis',\n",
    "       'camera_title_jaccard_dis', 'camera_title_overlap_dis',\n",
    "       'camera_title_edit_dis', 'camera_title_overlap_freq',\n",
    "       'camera_title_unmatch_freq', 'camera_title_numeric_jaccard_dis', 'camera_title_numeric_edit_dis'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(xxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(products_labeled[products_labeled['label'] == 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = list(products_labeled[products_labeled['label'] == 1].iloc[0:40000, 3:11].values) + list(products_labeled[products_labeled['label'] == 0].iloc[0:100000, 3:11].values)\n",
    "# train_overlap_freqs = list(products_labeled[products_labeled['label'] == 1].iloc[0:40000, 11:12].values) + list(products_labeled[products_labeled['label'] == 0].iloc[0:100000, 11:12].values)\n",
    "# train_unmatch_freqs = list(products_labeled[products_labeled['label'] == 1].iloc[0:40000, 12:13].values) + list(products_labeled[products_labeled['label'] == 0].iloc[0:100000, 12:13].values)\n",
    "# train_targets = list(products_labeled[products_labeled['label'] == 1].iloc[0:40000, 2:3].values) + list(products_labeled[products_labeled['label'] == 0].iloc[0:100000, 2:3].values)\n",
    "\n",
    "# test_features = list(products_labeled[products_labeled['label'] == 1].iloc[40000:, 3:11].values) + list(products_labeled[products_labeled['label'] == 0].iloc[100000:, 3:11].values)\n",
    "# test_overlap_freqs = list(products_labeled[products_labeled['label'] == 1].iloc[40000:, 11:12].values) + list(products_labeled[products_labeled['label'] == 0].iloc[100000:, 11:12].values)\n",
    "# test_unmatch_freqs = list(products_labeled[products_labeled['label'] == 1].iloc[40000:, 12:13].values) + list(products_labeled[products_labeled['label'] == 0].iloc[100000:, 12:13].values)\n",
    "# test_targets = list(products_labeled[products_labeled['label'] == 1].iloc[40000:, 2:3].values) + list(products_labeled[products_labeled['label'] == 0].iloc[100000:, 2:3].values)\n",
    "\n",
    "train_features = list(products_labeled[products_labeled['label']==1].iloc[:40000, 3:13].values) + list(products_labeled[products_labeled['label']==0].iloc[:100000, 3:13].values)\n",
    "train_overlap_freqs = list(products_labeled[products_labeled['label']==1].iloc[:40000, 13:14].values) + list(products_labeled[products_labeled['label']==0].iloc[:100000, 13:14].values)\n",
    "train_unmatch_freqs = list(products_labeled[products_labeled['label']==1].iloc[:40000, 14:15].values) + list(products_labeled[products_labeled['label']==0].iloc[:100000, 14:15].values)\n",
    "train_targets = list(products_labeled[products_labeled['label']==1].iloc[:40000, 2:3].values) + list(products_labeled[products_labeled['label']==0].iloc[:100000, 2:3].values)\n",
    "\n",
    "test_features = list(products_labeled[products_labeled['label']==1].iloc[40000:, 3:13].values) + list(products_labeled[products_labeled['label']==0].iloc[100000:, 3:13].values)\n",
    "test_overlap_freqs = list(products_labeled[products_labeled['label']==1].iloc[40000:, 13:14].values) + list(products_labeled[products_labeled['label']==0].iloc[100000:, 13:14].values)\n",
    "test_unmatch_freqs = list(products_labeled[products_labeled['label']==1].iloc[40000:, 14:15].values) + list(products_labeled[products_labeled['label']==0].iloc[100000:, 14:15].values)\n",
    "test_targets = list(products_labeled[products_labeled['label']==1].iloc[40000:, 2:3].values) + list(products_labeled[products_labeled['label']==0].iloc[100000:, 2:3].values)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        ProductsDataset(train_features, train_targets, train_overlap_freqs, train_unmatch_freqs), batch_size=256, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        ProductsDataset(test_features, test_targets, test_overlap_freqs, test_unmatch_freqs), batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "sequence_len = 1000\n",
    "sequence_len_title = 20\n",
    "class Dataset(object):\n",
    "    \"\"\"An abstract class representing a Dataset.\n",
    "\n",
    "    All other datasets should subclass it. All subclasses should override\n",
    "    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
    "    supporting integer indexing in range from 0 to len(self) exclusive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def generate_embeddings(words, seq_len):\n",
    "    embedding = []\n",
    "    for word in words:\n",
    "        if word in w2v:\n",
    "            embedding.append(w2v[word])\n",
    "#     print ('length: ', len(embedding), len(words))\n",
    "    if len(embedding) < seq_len:\n",
    "        if len(embedding) > 0:\n",
    "            mask = np.pad([[1] for _ in range(len(embedding))], ((0, seq_len-len(embedding)), (0,0)), 'constant')\n",
    "            embedding = np.pad(embedding, ((0, seq_len-len(embedding)), (0,0)), 'constant')\n",
    "        else:\n",
    "            mask = np.pad([[0]], ((0, seq_len-1), (0,0)), 'constant')\n",
    "            embedding = np.pad([[0 for _ in range(256)]], ((0, seq_len-1), (0,0)), 'constant')\n",
    "    else:\n",
    "        mask = np.array([[1] for _ in range(seq_len)])\n",
    "        embedding = np.array(embedding[0:seq_len])\n",
    "    return embedding, mask\n",
    "\n",
    "class ProductsDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping tensors.\n",
    "\n",
    "    Each sample will be retrieved by indexing tensors along the first dimension.\n",
    "\n",
    "    Arguments:\n",
    "        *tensors (Tensor): tensors that have the same size of the first dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *tensors):\n",
    "#         assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        distances = self.tensors[0][index]\n",
    "        targets = self.tensors[1][index]\n",
    "        overlap_freqs = str(self.tensors[2][index][0])\n",
    "        unmatch_freqs = str(self.tensors[3][index][0])\n",
    "        overlap_len = 12\n",
    "        unmatch_len = 30\n",
    "        if len(overlap_freqs) == 0:\n",
    "            overlap_freqs = '0.0'\n",
    "        if len(unmatch_freqs) == 0:\n",
    "            unmatch_freqs = '0.0'\n",
    "        overlap_array = str(overlap_freqs).split(';')[0:overlap_len]\n",
    "        unmatch_array = str(unmatch_freqs).split(';')[0:unmatch_len]\n",
    "        \n",
    "        overlap = np.pad([float(x) for x in overlap_array], (0, overlap_len-len(overlap_array)), 'constant')\n",
    "        unmatch = np.pad([float(x) for x in unmatch_array], (0, unmatch_len-len(unmatch_array)), 'constant')\n",
    "        return tuple([torch.FloatTensor(distances), torch.FloatTensor(targets), torch.FloatTensor(overlap), torch.FloatTensor(unmatch)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensors[0]) \n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "#     torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#         ProductsDataset(train_features, train_overlap_freqs, train_unmatch_freqs, train_targets), batch_size=1024, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#         ProductsDataset(test_features, test_overlap_freqs, test_unmatch_freqs, test_targets), batch_size=1024, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# train_loader2 = torch.utils.data.DataLoader(\n",
    "#         ProductsDataset2(), batch_size=128, shuffle=True)\n",
    "# test_loader2 = torch.utils.data.DataLoader(\n",
    "#         ProductsDataset2(), batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_size, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        hid = F.relu(self.linear1(features))\n",
    "        hid = F.relu(self.linear2(hid))\n",
    "        return hid\n",
    "    \n",
    "class Output(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_len):\n",
    "        super(Output, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_len, 256)\n",
    "        self.linear3 = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        inputs = torch.cat(embeddings, dim=1)\n",
    "        hid = F.relu(self.linear1(inputs))\n",
    "        hid = F.sigmoid(self.linear3(hid))\n",
    "        return hid\n",
    "\n",
    "def l1_loss(estimates, targets):\n",
    "#     targets = targets.unsqueeze(1)\n",
    "#     print (torch.cat((estimates, targets), 1))\n",
    "    return F.mse_loss(estimates, targets)\n",
    "#     return (-targets * (torch.log(estimates + 0.0001)) - (1.0 - targets) * (torch.log(1.0 - estimates + 0.0001))).mean()\n",
    "\n",
    "def print_loss(estimates, targets):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    for i in range(len(estimates)):\n",
    "        if estimates[i][0] >= 0.5 and targets[i] == 1:\n",
    "            true_positive += 1\n",
    "        elif estimates[i][0] < 0.5 and targets[i] == 1:\n",
    "            true_negative += 1\n",
    "        elif estimates[i][0] < 0.5 and targets[i] == 0:\n",
    "            false_negative += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    if true_positive + false_positive == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = float(true_positive) / (true_positive + false_positive)\n",
    "    if true_positive + true_negative == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = float(true_positive) / (true_positive + true_negative)\n",
    "    return precision, recall\n",
    "        \n",
    "# strctured_model = Model()\n",
    "# unstructured_model = bilstm_attn(128, 256, 256, 30000, 256, True, 0.1, use_cuda, 512, 1000)\n",
    "# title_model = bilstm_attn(128, 256, 256, 30000, 256, True, 0.1, use_cuda, 512, 20)\n",
    "# output_model = Output()\n",
    "\n",
    "# new_structured_model = Model()\n",
    "# new_title_model = Attention(128, 256, 256, 30000, 256, True, 0.1, use_cuda, 512, 20)\n",
    "# new_output_model = Output()\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# distance_model = Model(10)\n",
    "# overlap_model = Model(12)\n",
    "# unmatch_model = Model(30)\n",
    "# output_model = Output(384)\n",
    "\n",
    "# opt = optim.Adam([{'params':output_model.parameters()},{'params':distance_model.parameters()},{'params':overlap_model.parameters()},{'params':unmatch_model.parameters()}], lr=0.001)\n",
    "\n",
    "for e in range(20):\n",
    "    distance_model.train()\n",
    "    overlap_model.train()\n",
    "    unmatch_model.train()\n",
    "    output_model.train()\n",
    "    for batch_idx, (distances, targets, overlaps, unmatches) in enumerate(train_loader):\n",
    "        distance = Variable(distances)\n",
    "        target = Variable(targets)\n",
    "        overlap = Variable(overlaps)\n",
    "        unmatch = Variable(unmatches)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        distance_embedding = distance_model(distance)\n",
    "        overlap_embedding = overlap_model(overlap)\n",
    "        unmatch_embedding = unmatch_model(unmatch)\n",
    "        \n",
    "        estimates = output_model([distance_embedding, overlap_embedding, unmatch_embedding])\n",
    "        loss = l1_loss(estimates, targets)\n",
    "        print('Training: Iteration {0}, Batch {1}, Loss {2}'.format(e, batch_idx, loss.item()))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    distance_model.eval()\n",
    "    overlap_model.eval()\n",
    "    unmatch_model.eval()\n",
    "    output_model.eval()\n",
    "    for batch_idx, (distances, targets, overlaps, unmatches) in enumerate(test_loader):\n",
    "        distance = Variable(distances)\n",
    "        target = Variable(targets)\n",
    "        overlap = Variable(overlaps)\n",
    "        unmatch = Variable(unmatches)\n",
    "        \n",
    "        distance_embedding = distance_model(distance)\n",
    "        overlap_embedding = overlap_model(overlap)\n",
    "        unmatch_embedding = unmatch_model(unmatch)\n",
    "        \n",
    "        estimates = output_model([distance_embedding, overlap_embedding, unmatch_embedding])\n",
    "        loss = l1_loss(estimates, targets)\n",
    "        \n",
    "        prec, rec = print_loss(estimates, targets)\n",
    "        \n",
    "        print('Testing: Batch {}, Loss {}, Precision {}, Recall {}'.format(batch_idx, loss.item(), prec, rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pairs = candidate_pairs.sample(n=10000, random_state=7)\n",
    "feature_extraction(test_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "        ProductsDataset(candidate_pairs.iloc[:, 4:14].values, candidate_pairs.iloc[:, 5:6].values, candidate_pairs.iloc[:, 14:15].values,candidate_pairs.iloc[:, 15:16].values), batch_size=1000, shuffle=False)\n",
    "\n",
    "distance_model.eval()\n",
    "overlap_model.eval()\n",
    "unmatch_model.eval()\n",
    "output_model.eval()\n",
    "\n",
    "scores = []\n",
    "matches = 0\n",
    "\n",
    "for batch_idx, (distances, targets, overlaps, unmatches) in enumerate(data_loader):\n",
    "    distance = Variable(distances)\n",
    "    target = Variable(targets)\n",
    "    overlap = Variable(overlaps)\n",
    "    unmatch = Variable(unmatches)\n",
    "\n",
    "    distance_embedding = distance_model(distance)\n",
    "    overlap_embedding = overlap_model(overlap)\n",
    "    unmatch_embedding = unmatch_model(unmatch)\n",
    "    \n",
    "    estimates = output_model([distance_embedding, overlap_embedding, unmatch_embedding])\n",
    "    \n",
    "    for i in range(estimates.shape[0]):\n",
    "        predict = estimates[i].item()\n",
    "        if predict >= 0.5:\n",
    "            matches += 1\n",
    "        scores.append(predict)\n",
    "    print ('Matching Pairs: {}, Total Pairs: {}'.format(matches, batch_idx * 1000))\n",
    "    \n",
    "# ['scores'] = scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs['scores'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs[candidate_pairs['scores'] >= 0.6][['left_spec_id', 'right_spec_id']].to_csv('submit_v8.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs[candidate_pairs['scores'] >= 0.999][['left_spec_id', 'right_spec_id']].to_csv('submit_v10.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(strctured_model.state_dict(), 'structured.model')\n",
    "# torch.save(title_model.state_dict(), 'title.model')\n",
    "# torch.save(output_model.state_dict(), 'output.model')\n",
    "\n",
    "# torch.save(distances_model.state_dict(), 'distances_model.model')\n",
    "# torch.save(freqs_model.state_dict(), 'freqs_model.model')\n",
    "\n",
    "torch.save(distance_model.state_dict(), 'distance_model.model')\n",
    "torch.save(overlap_model.state_dict(), 'overlap_model.model')\n",
    "torch.save(unmatch_model.state_dict(), 'unmatch_model.model')\n",
    "torch.save(output_model.state_dict(), 'output_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_model = Model(10)\n",
    "overlap_model = Model(12)\n",
    "unmatch_model = Model(30)\n",
    "output_model = Output(384)\n",
    "\n",
    "distance_model.load_state_dict(torch.load('distance_model.model'))\n",
    "overlap_model.load_state_dict(torch.load('overlap_model.model'))\n",
    "unmatch_model.load_state_dict(torch.load('unmatch_model.model'))\n",
    "output_model.load_state_dict(torch.load('output_model.model'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candidates = pd.read_csv('/home/sunji/EM_sigmod/quickstart_package/candidate_pairs_key.csv')\n",
    "labeled = pd.read_csv('/home/sunji/EM_sigmod/sigmod_large_labelled_dataset.csv')\n",
    "# structured_data = pd.read_csv('total_with_key_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled.join(structured_data[['type', 'type_number', 'blocking_key', 'page_title', 'version']], on='left_spec_id', how='inner').join(structured_data[['type', 'type_number', 'blocking_key', 'page_title', 'version']], on='right_spec_id', how='inner', lsuffix='_left', rsuffix='_right').to_csv('/home/sunji/EM_sigmod/quickstart_package/label_pairs_with_key_type.csv', index=False)\n",
    "candidates.join(structured_data[['type', 'type_number', 'blocking_key', 'page_title', 'version']], on='left_spec_id', how='inner').join(structured_data[['type', 'type_number', 'blocking_key', 'page_title', 'version']], on='right_spec_id', how='inner', lsuffix='_left', rsuffix='_right').to_csv('/home/sunji/EM_sigmod/quickstart_package/candidate_pairs_with_key_type.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xxxx = pd.read_csv('/home/sunji/EM_sigmod/sigmod_large_labelled_dataset.csv')\n",
    "# xxxx = pd.read_csv('/home/sunji/EM_sigmod/quickstart_package/output/submission.csv')\n",
    "xxxx = pd.read_csv('/home/sunji/EM_sigmod/miss.csv')\n",
    "# xxxx2 = pd.read_csv('/home/sunji/EM_sigmod/submit_v32_99_98_99.csv')\n",
    "# xxxx = pd.read_csv('/home/sunji/EM_sigmod/submit_v27_97_98_97.csv')\n",
    "# xxxx.columns = ['left_spec_id', 'right_spec_id', 'left_spec_title', 'right_spec_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx = xxxx.join(structured_data[['type', 'type_number', 'blocking_key', 'page_title', 'version']], on='left_spec_id', how='inner').join(structured_data[['type', 'type_number', 'blocking_key', 'page_title', 'version']], on='right_spec_id', how='inner', lsuffix='_left', rsuffix='_right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx3 = xxxx3.join(structured_data[['type', 'type_number', 'blocking_key', 'page_title', 'version']], on='left_spec_id', how='inner').join(structured_data[['type', 'type_number', 'blocking_key', 'page_title', 'version']], on='right_spec_id', how='inner', lsuffix='_left', rsuffix='_right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx.to_csv('/home/sunji/EM_sigmod/quickstart_package/label_pairs_with_key_type.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx.to_csv('/home/sunji/EM_sigmod/quickstart_package/candidate_pairs_with_key_type.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51a60c3a6da446a92f0feb34e63a45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=568316.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def swap(row):\n",
    "    if row['left_spec_id'] > row['right_spec_id']:\n",
    "        tmp = row['left_spec_id']\n",
    "        row['left_spec_id'] = row['right_spec_id']\n",
    "        row['right_spec_id'] = tmp\n",
    "    return row\n",
    "\n",
    "xxxx2 = xxxx2.swifter.apply(lambda x: swap(x), axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx = xxxx.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx3 = xxxx2.append(xxxx).append(xxxx).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx.to_csv('/home/sunji/EM_sigmod/pairs_with_key_type.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4360"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_spec_id</th>\n",
       "      <th>right_spec_id</th>\n",
       "      <th>type_left</th>\n",
       "      <th>type_number_left</th>\n",
       "      <th>blocking_key_left</th>\n",
       "      <th>page_title_left</th>\n",
       "      <th>version_left</th>\n",
       "      <th>type_right</th>\n",
       "      <th>type_number_right</th>\n",
       "      <th>blocking_key_right</th>\n",
       "      <th>page_title_right</th>\n",
       "      <th>version_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>www.alibaba.com//36840</td>\n",
       "      <td>www.alibaba.com//25317</td>\n",
       "      <td>effioe;products!!10</td>\n",
       "      <td>10</td>\n",
       "      <td>sony</td>\n",
       "      <td>excellent products!!10m ir dome cmos cctv secu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sony</td>\n",
       "      <td>top 10 cctv camera factory china 1/3'sony supe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>www.alibaba.com//36840</td>\n",
       "      <td>www.alibaba.com//27445</td>\n",
       "      <td>effioe;products!!10</td>\n",
       "      <td>10</td>\n",
       "      <td>sony</td>\n",
       "      <td>excellent products!!10m ir dome cmos cctv secu...</td>\n",
       "      <td></td>\n",
       "      <td>hs7362</td>\n",
       "      <td>7362</td>\n",
       "      <td>sony</td>\n",
       "      <td>top 10 cctv camera sony ccd 2.8-12mm vari foca...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>www.alibaba.com//24953</td>\n",
       "      <td>www.alibaba.com//24592</td>\n",
       "      <td>effiov</td>\n",
       "      <td></td>\n",
       "      <td>sony</td>\n",
       "      <td>ir waterproof sony effio-v 800tvl wdr camera -...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sony</td>\n",
       "      <td>1/3 sony ccd high focus 700tvl cctv dome camer...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>www.alibaba.com//7632</td>\n",
       "      <td>www.alibaba.com//24592</td>\n",
       "      <td>effiov</td>\n",
       "      <td></td>\n",
       "      <td>sony</td>\n",
       "      <td>sony effio-v wdr 800tvl security camera,wather...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sony</td>\n",
       "      <td>1/3 sony ccd high focus 700tvl cctv dome camer...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>www.alibaba.com//36840</td>\n",
       "      <td>www.alibaba.com//25971</td>\n",
       "      <td>effioe;products!!10</td>\n",
       "      <td>10</td>\n",
       "      <td>sony</td>\n",
       "      <td>excellent products!!10m ir dome cmos cctv secu...</td>\n",
       "      <td></td>\n",
       "      <td>twdir004s480</td>\n",
       "      <td>004480</td>\n",
       "      <td>sony</td>\n",
       "      <td>outdoor waterproof 480tvl cctv sony digital ca...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>www.alibaba.com//36840</td>\n",
       "      <td>www.alibaba.com//35226</td>\n",
       "      <td>effioe;products!!10</td>\n",
       "      <td>10</td>\n",
       "      <td>sony</td>\n",
       "      <td>excellent products!!10m ir dome cmos cctv secu...</td>\n",
       "      <td></td>\n",
       "      <td>480/600tvl</td>\n",
       "      <td>480600</td>\n",
       "      <td>sony</td>\n",
       "      <td>480/600tvl 1/4 sony ccd box camera for home se...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>www.alibaba.com//36840</td>\n",
       "      <td>www.alibaba.com//37218</td>\n",
       "      <td>effioe;products!!10</td>\n",
       "      <td>10</td>\n",
       "      <td>sony</td>\n",
       "      <td>excellent products!!10m ir dome cmos cctv secu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sony</td>\n",
       "      <td>sony ccd 480tvl ir digital color waterproof bu...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               left_spec_id           right_spec_id            type_left  \\\n",
       "543  www.alibaba.com//36840  www.alibaba.com//25317  effioe;products!!10   \n",
       "545  www.alibaba.com//36840  www.alibaba.com//27445  effioe;products!!10   \n",
       "194  www.alibaba.com//24953  www.alibaba.com//24592               effiov   \n",
       "597   www.alibaba.com//7632  www.alibaba.com//24592               effiov   \n",
       "544  www.alibaba.com//36840  www.alibaba.com//25971  effioe;products!!10   \n",
       "546  www.alibaba.com//36840  www.alibaba.com//35226  effioe;products!!10   \n",
       "547  www.alibaba.com//36840  www.alibaba.com//37218  effioe;products!!10   \n",
       "\n",
       "    type_number_left blocking_key_left  \\\n",
       "543               10              sony   \n",
       "545               10              sony   \n",
       "194                               sony   \n",
       "597                               sony   \n",
       "544               10              sony   \n",
       "546               10              sony   \n",
       "547               10              sony   \n",
       "\n",
       "                                       page_title_left version_left  \\\n",
       "543  excellent products!!10m ir dome cmos cctv secu...                \n",
       "545  excellent products!!10m ir dome cmos cctv secu...                \n",
       "194  ir waterproof sony effio-v 800tvl wdr camera -...                \n",
       "597  sony effio-v wdr 800tvl security camera,wather...                \n",
       "544  excellent products!!10m ir dome cmos cctv secu...                \n",
       "546  excellent products!!10m ir dome cmos cctv secu...                \n",
       "547  excellent products!!10m ir dome cmos cctv secu...                \n",
       "\n",
       "       type_right type_number_right blocking_key_right  \\\n",
       "543                                               sony   \n",
       "545        hs7362              7362               sony   \n",
       "194                                               sony   \n",
       "597                                               sony   \n",
       "544  twdir004s480            004480               sony   \n",
       "546    480/600tvl            480600               sony   \n",
       "547                                               sony   \n",
       "\n",
       "                                      page_title_right version_right  \n",
       "543  top 10 cctv camera factory china 1/3'sony supe...                \n",
       "545  top 10 cctv camera sony ccd 2.8-12mm vari foca...                \n",
       "194  1/3 sony ccd high focus 700tvl cctv dome camer...                \n",
       "597  1/3 sony ccd high focus 700tvl cctv dome camer...                \n",
       "544  outdoor waterproof 480tvl cctv sony digital ca...                \n",
       "546  480/600tvl 1/4 sony ccd box camera for home se...                \n",
       "547  sony ccd 480tvl ir digital color waterproof bu...                "
      ]
     },
     "execution_count": 1243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xxxx[(xxxx['blocking_key_left'] == 'sony') & xxxx['page_title_left'].str.contains('effio')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_title</th>\n",
       "      <th>camera_brand</th>\n",
       "      <th>camera_model</th>\n",
       "      <th>camera_mpn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blocking_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>absee</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aiptek</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aquapix</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argus</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asus</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barbie</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bell+howell</th>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benq</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blackmagic</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brinno</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bushnell</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cannon</th>\n",
       "      <td>5495</td>\n",
       "      <td>4231</td>\n",
       "      <td>3700</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbose</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casio</th>\n",
       "      <td>224</td>\n",
       "      <td>166</td>\n",
       "      <td>154</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coleman</th>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contax</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crayola</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>croco</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dahua</th>\n",
       "      <td>639</td>\n",
       "      <td>0</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digital blue</th>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disney</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dongjia</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drift</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxg</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easypix</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerson</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enxun</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neopine</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nikon</th>\n",
       "      <td>4739</td>\n",
       "      <td>3544</td>\n",
       "      <td>3131</td>\n",
       "      <td>2451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nokia</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olympus</th>\n",
       "      <td>1458</td>\n",
       "      <td>1015</td>\n",
       "      <td>886</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panasonic</th>\n",
       "      <td>1318</td>\n",
       "      <td>858</td>\n",
       "      <td>653</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pentax</th>\n",
       "      <td>613</td>\n",
       "      <td>447</td>\n",
       "      <td>385</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philips</th>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polaroid</th>\n",
       "      <td>117</td>\n",
       "      <td>103</td>\n",
       "      <td>92</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ricoh</th>\n",
       "      <td>103</td>\n",
       "      <td>72</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rollei</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sakar</th>\n",
       "      <td>228</td>\n",
       "      <td>193</td>\n",
       "      <td>180</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>1073</td>\n",
       "      <td>727</td>\n",
       "      <td>624</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samyang</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanyo</th>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sealife</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharp</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>101</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sony</th>\n",
       "      <td>3233</td>\n",
       "      <td>2269</td>\n",
       "      <td>2032</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superheadz</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svp</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sylvania</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tamron</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toshiba</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vistaquest</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vizio</th>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vtech</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wespro</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wopson</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yashica</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              page_title  camera_brand  camera_model  camera_mpn\n",
       "blocking_key                                                    \n",
       "absee                 26             0             0           0\n",
       "aiptek                11            10             9           6\n",
       "apple                 70             3             4           2\n",
       "aquapix                1             1             1           0\n",
       "argus                  8             8             7           5\n",
       "asus                   1             1             0           0\n",
       "barbie                 4             4             4           0\n",
       "bell+howell           57            21            31          18\n",
       "benq                  15            10             6           4\n",
       "blackmagic             8             6             4           3\n",
       "brinno                 3             3             3           3\n",
       "bushnell               3             3             3           3\n",
       "cannon              5495          4231          3700        2825\n",
       "carbose               63            63             0           0\n",
       "casio                224           166           154         110\n",
       "cobra                 12            11            11           6\n",
       "coleman               41            24            31          17\n",
       "contax                 3             3             2           1\n",
       "crayola                3             3             1           2\n",
       "croco                 34             0             0           0\n",
       "dahua                639             0           611           0\n",
       "digital blue          19            15            15          13\n",
       "disney                12             9             6           5\n",
       "dji                    6             3             3           2\n",
       "dongjia                2             0             0           0\n",
       "drift                  7             2             2           0\n",
       "dxg                   15            12            11           4\n",
       "easypix                9             9             8           1\n",
       "emerson               12            10             8           2\n",
       "enxun                 34             0             0           0\n",
       "...                  ...           ...           ...         ...\n",
       "neopine               15             1             1           0\n",
       "nikon               4739          3544          3131        2451\n",
       "nokia                  2             1             1           0\n",
       "olympus             1458          1015           886         665\n",
       "panasonic           1318           858           653         431\n",
       "pentax               613           447           385         201\n",
       "philips               19            17            13          10\n",
       "polaroid             117           103            92          65\n",
       "ricoh                103            72            56          41\n",
       "rollei                 2             2             2           0\n",
       "sakar                228           193           180         118\n",
       "samsung             1073           727           624         443\n",
       "samyang               18             0             1           0\n",
       "sanyo                 46            45            44          36\n",
       "sealife               16            15            14           9\n",
       "sharp                 17            15            11          10\n",
       "sigma                101            22            18          13\n",
       "sony                3233          2269          2032        1402\n",
       "superheadz             8             7             7           7\n",
       "svp                   51            51             9           2\n",
       "sylvania               6             4             5           2\n",
       "tamron                52             5            23           0\n",
       "toshiba               19            18            17          10\n",
       "vibe                   4             4             2           0\n",
       "vistaquest            12            11            10           6\n",
       "vizio                 37            35            31          25\n",
       "vtech                 10             7             7           2\n",
       "wespro                 4             3             3           0\n",
       "wopson                13             0             0           0\n",
       "yashica                5             3             3           0\n",
       "\n",
       "[87 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter(row):\n",
    "    if re.findall(r'^\\d+', row['type']):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def filter2(row):\n",
    "    if row['type'] == '':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def filter3(row):\n",
    "    if 'f505' in str(row['page_title']):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# structured_data[(structured_data['blocking_key'] == 'sony') & structured_data.apply(lambda x: filter(x), axis=1)]\n",
    "# structured_data.loc['www.ebay.com//48550']['page_title']\n",
    "structured_data.groupby('blocking_key')\n",
    "# structured_data.groupby('blocking_key').count().sort_values(by='page_title')\n",
    "# structured_data.loc['www.alibaba.com//24172']['page_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findlong(x):\n",
    "    return len(str(x['type']).split(';')) == 1\n",
    "\n",
    "def findlong2(x):\n",
    "    return len(str(x['type'])) == 0\n",
    "# xxxx[(xxxx['left_spec_id'] == 'www.eglobalcentral.co.uk//713') & (xxxx['right_spec_id'] == 'www.eglobalcentral.co.uk//637')]\n",
    "x = structured_data[structured_data.apply(lambda row: findlong2(row), axis=1)]\n",
    "x[x['source'] != 'www.alibaba.com'].sample(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopped_words = set(['bin2','cam','ixus','pro','rebel','shot','cyber','catalog','stylus','mark','edition','elph','','digital camera', 'camera','wide','model','sport','network','action','full','ir','mini','metal','digital camera', 'indoor', 'canon eos', 'compact', 'digital', 'digital rebel', 'case', 'lcd', 'panasonic lumix', 'slr', 'cybershot', 'hd', '3x', '4x', '5x', '3gp', '']) | all_brands\n",
    "\n",
    "def filter_accessary(words, keyword):\n",
    "    try:\n",
    "        pos = words.index(keyword)\n",
    "        return len(set(words[0:pos]) & all_brands) > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def is_type(words, idx, current_num, current_num2):\n",
    "#     if len(words) > 3:\n",
    "#         return True\n",
    "#     print (set(words[0:idx]) & all_brands, words[idx], current_num)\n",
    "    exist_number_match = re.findall(r'[0-9]+', words[idx])\n",
    "    only_number_match = re.findall(r'^[0-9]+$', words[idx])\n",
    "    possible_mpn_match = re.findall(r'\\d{4}', words[idx])\n",
    "    letter_match = re.findall(r'[a-z]+', words[idx])\n",
    "    stop_match = re.findall(r'[\"$\\']+', words[idx])\n",
    "    if 'comparison' in words[0:idx] and filter_accessary(words, 'comparison') and current_num2 > 0: # Kit is not important\n",
    "        return False\n",
    "    if 'kit' in words[0:idx] and filter_accessary(words, 'kit') and current_num2 > 0: # Kit is not important\n",
    "        return False\n",
    "    if '&' in words[0:idx] and filter_accessary(words, '&') and current_num2 > 0: # Kit is not important\n",
    "        return False\n",
    "    if '+' in words[0:idx] and filter_accessary(words, '+') and current_num2 > 0: # Kit is not important\n",
    "        return False\n",
    "    if 'w/' in words[0:idx] and filter_accessary(words, 'w/') and current_num2 > 0: # Kit is not important\n",
    "        return False\n",
    "    if 'w' in words[0:idx] and filter_accessary(words, 'w') and current_num2 > 0: # Kit is not important\n",
    "        return False\n",
    "    if 'with' in words[0:idx] and filter_accessary(words, 'with') and current_num2 > 0: # Kit is not important\n",
    "        return False\n",
    "    if len(words[idx]) > 20:\n",
    "        return False\n",
    "    if not exist_number_match and words[idx] not in ['effio','effioe','effioa','effiop','effio-a','effio-v','effios','effiov','effio-s','effio-e','effio-p','n', 'r', 'xsi', 'z', 'a', 'xti', 'xt', 'eos-m', 'eosm', 'i','ii','iii','vi','iv', 'iis', 'markii', 'markiii', 'mkii', 'mkiii','slv', 'df', 'q', 'm', 'x', 'nx', 'xs', 'k-x', 'k-r', 'xs-pro', 'v', 'gr', 'px']: # No number, cannot be type\n",
    "        return False\n",
    "    if only_number_match and (len(set(words[0:idx]) & all_brands) == 0 or len(words[idx]) > 4):\n",
    "        return False\n",
    "    if words[idx] in ['960h','m43', '1080p', '960p', '720p', '360p', 'h.264', 'p2p', '20x', 'ip66', 'mpeg4', '1/3']:\n",
    "        return False\n",
    "    if not letter_match:\n",
    "        if stop_match: # money, size etc.\n",
    "            return False\n",
    "        if idx < len(words)-1 and (words[idx+1] in ['tvl', 'meapixels', 'mg', 'batteries', 'gb', 'lens', 'meters', 'mm', 'mp', 'inch', 'megapixel', 'megapixels', 'mega', 'pack']):\n",
    "            return False\n",
    "#         if not possible_mpn_match:\n",
    "        if len(set(words[max(0, idx-2):idx]) & all_brands) == 0 and words[idx-1] not in ['rebel', 'finepix'] or (words[idx-2] == 'eos' and words[idx-1] != 'rebel') or words[idx-2] == 'finepix': # no adjacent brand\n",
    "            if current_num >= 1 and words[idx-1] != 'mark':\n",
    "                return False\n",
    "            if idx < len(words)-1 and (words[idx+1].endswith('mm') or words[idx+1].endswith('mp') or words[idx+1].endswith('inch') or words[idx+1].endswith('megapixel') or words[idx+1].endswith('mega')):\n",
    "                return False\n",
    "            if only_number_match and idx < len(words)-2 and re.findall(r'^[0-9]+$', words[idx+1]):\n",
    "                if float(words[idx+1]) < 10 and (words[idx+2] in ['millions', 'mg', 'mp', 'inch', 'mega', 'megapixel']): # still a pixel, missing point\n",
    "                    return False\n",
    "                if float(words[idx]) < 300 and float(words[idx+1]) < 1000 and words[idx+2] in ['meters', 'mm', 'lens']: # still a len, missing point\n",
    "                    return False\n",
    "            if only_number_match and len(set(words[max(0, idx-4):idx]) & all_brands) == 0:\n",
    "                return False\n",
    "            if re.findall(r'[0-9]+\\-[0-9]+', words[idx]):\n",
    "                return False\n",
    "        else:\n",
    "            if only_number_match and idx > 0 and words[idx-1] in ['sony'] and words[idx+1].endswith('mp'):\n",
    "                return False\n",
    "            if only_number_match and idx < len(words)-2 and re.findall(r'^[0-9]+$', words[idx+1]):\n",
    "                if float(words[idx]) >= 10 and float(words[idx+1]) < 10 and (words[idx+2] in ['millions', 'mg', 'mp', 'inch', 'mega', 'megapixel']): # still a pixel, missing point\n",
    "                    return False\n",
    "                if float(words[idx]) < 300 and float(words[idx+1]) < 1000 and words[idx+2] in ['meters', 'mm', 'lens']: # still a len, missing point\n",
    "                    return False\n",
    "                if float(words[idx+1]) == 0:\n",
    "                    return False\n",
    "#             if current_num >= 1 and idx < len(words)-1 and (words[idx+1] in ['mm','mp','meters','inch','megapixel','mega'] or (words[idx+1].endswith('mm') or words[idx+1].endswith('mp') or words[idx+1].endswith('inch') or words[idx+1].endswith('megapixel') or words[idx+1].endswith('mega')) and float(''.join(re.findall(r'\\d+', words[idx+1]))) < 10):\n",
    "#                 return False\n",
    "            if current_num >= 1 and idx < len(words)-1 and (words[idx+1] in ['millions', 'mg', 'mm','mp','meters','inch','megapixel','mega'] or (words[idx+1].endswith('mm') or words[idx+1].endswith('mp') or words[idx+1].endswith('inch') or words[idx+1].endswith('megapixel') or words[idx+1].endswith('mega')) and float(''.join(re.findall(r'\\d+', words[idx+1]))) < 10):\n",
    "                return False\n",
    "            if idx < len(words)-1 and (words[idx+1] in ['millions', 'mg', 'mm','mp','meters','inch','megapixel','mega'] or (words[idx+1].endswith('mg') or words[idx+1].endswith('mm') or words[idx+1].endswith('mp') or words[idx+1].endswith('inch') or words[idx+1].endswith('megapixel') or words[idx+1].endswith('mega')) and float(''.join(re.findall(r'\\d+', words[idx+1]))) == 0):\n",
    "                return False\n",
    "        if words[idx] in ['2015', '2014', '2013', '2012', '2011']:\n",
    "            return False\n",
    "    else:\n",
    "#         print (words[idx])\n",
    "        if words[idx] in ['i', 'ii', 'iii', 'iv'] and 'camera' not in ''.join(words[max(0,idx-2):idx]) and (idx > 0 and words[idx-1] not in ['mark', 'mk']) and ('af-s' in words[0:idx] or (idx < len(words)-1 and words[idx+1] == 'lens') or len(set(words[max(0, idx-4):idx]) & all_brands) == 0):\n",
    "            return False\n",
    "        if words[idx] in ['iis', 'z', 'm', 'x', 'df', 'f1', 'gr', 'px', 'slv', 'xs', 'k-x', 'k-r', 'xs-pro', 'v', 'q'] and (len(set(words[max(0, idx-4):idx]) & all_brands) == 0 or current_num > 0):\n",
    "            return False\n",
    "        if words[idx] in ['nx'] and words[idx+1] != 'mini':\n",
    "            return False\n",
    "        if (re.findall(r'\\d*\\.?\\d*\\-?\\d*\\.?\\d*mm$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*mp$', words[idx]) or\n",
    "           re.findall(r'^\\d+\\.?\\d*\\-?\\d*\\.?\\d*m$', words[idx]) or\n",
    "           re.findall(r'\\d+\\.?\\d*\\-?\\d*\\.?\\d*meter$', words[idx]) or\n",
    "           re.findall(r'^\\d+\\.?\\d*\\-?\\d*\\.?\\d*cm$', words[idx]) or\n",
    "           re.findall(r'\\d*\\.?\\d*\\-?\\d*\\.?\\d*megpixel$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*cmos$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*pcs$', words[idx]) or \n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*mb/s$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*pc$', words[idx]) or\n",
    "           re.findall(r'\\d*\\.?\\d*\\-?\\d*\\.?\\d*inch$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*gb$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*g$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*fps$', words[idx]) or\n",
    "           re.findall(r'\\d*\\.?\\d*\\-?\\d*\\.?\\d*megapixel$', words[idx]) or\n",
    "           re.findall(r'\\d*\\.?\\d*\\-?\\d*\\.?\\d*digital$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*mega$', words[idx]) or\n",
    "           re.findall(r'\\d*\\.?\\d*\\-?\\d*\\.?\\d*megapixels$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*year$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*yr$', words[idx]) or\n",
    "           re.findall(r'^s\\d+\\.?\\d*\\-\\d+\\.?\\d*$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*g?hz$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*lens$', words[idx]) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*colors?$', words[idx]) or\n",
    "           re.findall(r'\\d+tvl$', words[idx]) or\n",
    "           re.findall(r'ip\\d*$', words[idx])):\n",
    "#             print (words[idx])\n",
    "            return False\n",
    "        if words[idx].startswith('sel') or words[idx].startswith('sal') or words[idx].endswith('batteries'):\n",
    "            return False\n",
    "        if re.findall(r'[0-9]+\\-[0-9]+\\/[0-9]+-[0-9]+$', words[idx]):\n",
    "            return False\n",
    "        if re.findall(r'^f\\/[0-9]+\\.?[0-9]*', words[idx]):\n",
    "            return False\n",
    "        if re.findall(r'^f\\/?[0-9]+\\.?[0-9]*$', words[idx]) and len(set(words[max(0, idx-2):idx]) & all_brands) == 0:\n",
    "            return False\n",
    "        if re.findall(r'^f\\/?[0-9]+\\.?[0-9]*\\-[0-9]+\\.?[0-9]*', words[idx]):\n",
    "            return False\n",
    "        if stop_match:\n",
    "            return False\n",
    "        if re.findall(r'^[0-9]+\\.?[0-9]*x$', words[idx]) and len(set(words[max(0, idx-2):idx]) & all_brands) == 0:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def verify_model(word, current_size):\n",
    "#     print (word)\n",
    "    if re.findall(r'\\d+', word) and current_size > 0:\n",
    "#         print ('here')\n",
    "        return False\n",
    "    if (re.findall(r'\\d*\\.?\\d*\\-?\\d*\\.?\\d*mm$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*mp$', word) or\n",
    "           re.findall(r'\\d+\\.?\\d*\\-?\\d*\\.?\\d*m$', word) or\n",
    "           re.findall(r'\\d+\\.?\\d*\\-?\\d*\\.?\\d*cm$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*megpixel$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*mega$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*cmos$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*pcs$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*pc$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*inch$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*gb$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*g$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*fps$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*megapixel$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*megapixels$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*year$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*yr$', word) or\n",
    "           re.findall(r'^s\\d+\\.?\\d*\\-\\d+\\.?\\d*$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*g?hz$', word) or\n",
    "           re.findall(r'^\\d*\\.?\\d*\\-?\\d*\\.?\\d*lens$', word) or\n",
    "           re.findall(r'ip\\d*$', word)):\n",
    "#         print ('here2')\n",
    "        return False\n",
    "    if word in ['1080p', '720p', '360p', 'h.264', 'p2p']:\n",
    "        return False\n",
    "    if word.startswith('sel') or word.startswith('sal'):\n",
    "        return False\n",
    "    if re.findall(r'[0-9]+\\-[0-9]+\\/[0-9]+-[0-9]+$', word):\n",
    "        return False\n",
    "    if re.findall(r'^f\\/[0-9]+\\.?[0-9]*', word):\n",
    "        return False\n",
    "    if re.findall(r'^f\\/?[0-9]+\\.?[0-9]*$', word):\n",
    "        return False\n",
    "    if re.findall(r'^f\\/?[0-9]+\\.?[0-9]*\\-[0-9]+\\.?[0-9]*', word):\n",
    "        return False\n",
    "    if re.findall(r'^[0-9]+\\.?[0-9]*x$', word):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def tfidf(x):\n",
    "#     print (x)\n",
    "    if x in word_tfidf:\n",
    "        return word_tfidf[x]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def extract_type(row):\n",
    "    words = re.split(r'[, ()~]', str(row['page_title']))\n",
    "    brand = str(row['blocking_key'])\n",
    "    words = [x.strip(',;-().') for x in words]\n",
    "    types = []\n",
    "    version = None\n",
    "    generations = {'i':'1','ii':'2','iii':'3','iv':'4'}\n",
    "    generations2 = {'i':'one','ii':'two','iii':'three','iv':'four'}\n",
    "    keep_num = 2\n",
    "#     print (words)\n",
    "    for idx, w in enumerate(words):\n",
    "#         print (w)\n",
    "        if w in types:\n",
    "            continue\n",
    "        if is_type(words, idx, len(re.findall(r'\\d+', ''.join(types))), len(types)):\n",
    "            if w in ['i','ii','iii','iv']:\n",
    "                if version is None:\n",
    "                    version = generations[w]\n",
    "                if len(types) == 0:\n",
    "                    types.append(generations2[w])\n",
    "            elif w in ['v2'] and 'coolpix' in words:\n",
    "                pass\n",
    "            elif w in ['a']:\n",
    "                if idx > 0 and words[idx-1] == 'coolpix':\n",
    "                    types.append('a')\n",
    "            elif w in ['1d', 'eos1d', 'eos-1d'] and brand == 'cannon':\n",
    "                if words[idx+1] in ['s', 'x']:\n",
    "                    types.append('1d'+words[idx+1])\n",
    "                else:\n",
    "                    types.append('1dk')\n",
    "            elif w in ['markii', 'mkii']:\n",
    "                if version is None:\n",
    "                    version = '2'\n",
    "            elif w in ['markiii', 'mkiii']:\n",
    "                if version is None:\n",
    "                    version = '3'\n",
    "            elif w in ['y1'] and brand == 'kodak':\n",
    "                pass\n",
    "#             if re.findall(r'\\d+', w) or w in ['i','ii','iii','vi','iv']:\n",
    "#             elif w in ['i','ii','iii','iv']:\n",
    "#                 types.append(generations2[w])\n",
    "            elif w == 'm' and idx > 1 and words[idx-1] == 'eos':\n",
    "                types.append('eosm')\n",
    "            elif w == 'x' and idx > 1 and words[idx-1] == 'k':\n",
    "                types.append('kx')\n",
    "            elif w == 'r' and idx > 1 and words[idx-1] == 'k':\n",
    "                types.append('kr')\n",
    "            elif re.findall(r'^\\d+$', w) and idx > 0 and words[idx-1] == 'mark':\n",
    "                if version is None:\n",
    "                    version = words[idx]\n",
    "            elif re.findall(r'^\\d+$', w) and idx > 0 and re.findall(r'\\d+', words[idx-1]):\n",
    "                continue\n",
    "            elif brand == 'fuji':\n",
    "                if len(''.join(re.findall(r'\\d+', w))) > 5:\n",
    "                    continue\n",
    "                sentence = ''.join(words[0:min(10,len(words))])\n",
    "                if w != 'x':\n",
    "                    if 'instax' in sentence:\n",
    "                        if idx > 0 and ''.join(words[idx-1].split('-')) in ['mini', 'wide']:\n",
    "                            w = ''.join(words[idx-1].split('-'))+w\n",
    "                    else:\n",
    "                        if idx < len(words)-1 and words[idx+1] in ['exr', 'f', 'v', 'pro', 'zoom']:\n",
    "                            w = w+words[idx+1]\n",
    "                        if idx > 0 and ''.join(words[idx-1].split('-')) in ['ds', 'mx', 'jx', 'av', 'ax', 'hs', '3d', 's', 'f', 'a', 'e', 't', 'j', 'z', 'xp', 'x', 'pro', 'xt', 'xe', 'xa', 'xpro']:\n",
    "                            w = ''.join(words[idx-1].split('-'))+w\n",
    "                    if not re.findall(r'^\\d+$', w) or len(w) >= 2:\n",
    "                        types.append(w)\n",
    "            elif brand == 'cannon':\n",
    "                if len(''.join(re.findall(r'\\d+', w))) > 5:\n",
    "                    continue\n",
    "                sentence = ''.join(words[0:min(10,len(words))])\n",
    "                if 'powershot' in sentence or 'ixus' in sentence or 'elph' in sentence or 'ixy' in sentence:\n",
    "                    if idx < len(words)-1 and words[idx+1] in ['zoom', 'is', 'x', 'a', 's', 'f', 'hs']:\n",
    "                        w = w+words[idx+1]\n",
    "                    if idx > 0 and words[idx-1] in ['sx', 'ixy','pro', 'a', 'g', 's', 'sd', 'ixus', 'elph']:\n",
    "                        w = words[idx-1]+w\n",
    "                elif 'eos' in sentence:\n",
    "                    if idx < len(words)-1 and words[idx+1] in ['d', 'ds', 'dx', 'dsr', 'da', 'v']:\n",
    "                        w = w+words[idx+1]\n",
    "                    if idx > 0 and words[idx-1] in ['m', 'ds', 'kiss']:\n",
    "                        w = words[idx-1]+w\n",
    "                else:\n",
    "                    if idx < len(words)-1 and words[idx+1] in ['d', 'ds', 'dx', 'dsr', 'da', 'v']:\n",
    "                        w = w+words[idx+1]\n",
    "                    if idx > 0 and words[idx-1] in ['m', 'ds', 'sd', 'kiss']:\n",
    "                        w = words[idx-1]+w\n",
    "                if not re.findall(r'^\\d+$', w) or len(w) >= 2:\n",
    "                    types.append(w)\n",
    "            elif brand == 'nikon':\n",
    "                if len(''.join(re.findall(r'\\d+', w))) > 5:\n",
    "                    continue\n",
    "#                 sentence = ''.join(words[0:min(10,len(words))])\n",
    "                if idx < len(words)-1 and words[idx+1] in ['a', 's', 'as', 't', 'hp', 'p', 'h', 'af', 'm', 'x']:\n",
    "                    w = w+words[idx+1]\n",
    "                if idx > 0 and words[idx-1] in ['s', 'aw', 'd', 'f', 'fa', 'fg', 'fe', 'fm', 'v', 'j', 'z']:\n",
    "                    w = words[idx-1]+w\n",
    "                if not re.findall(r'^\\d+$', w) or len(w) >= 2:\n",
    "                    types.append(w)\n",
    "            elif brand == 'olympus':\n",
    "#                 print (w)\n",
    "                if len(''.join(re.findall(r'\\d+', w))) > 5:\n",
    "                    continue\n",
    "                sentence = ''.join(words[0:min(10,len(words))])\n",
    "                if idx < len(words)-1 and words[idx+1] in ['rs', 'wp', 'sw', 'ee', 'x']:\n",
    "                    w = w+words[idx+1]\n",
    "                    \n",
    "                if idx > 0 and words[idx-1] in ['c' or 'camedia']:\n",
    "                    w = 'c'+w\n",
    "                elif idx > 0 and ''.join(words[idx-1].split('-')) in ['xz', 'vh','t','vr','vg','sz', 'x', 'ir', 'sp', 'd', 'e', 'f', 'fe', 'p', 'ep', 'tough', 'tg', 'e', 'em']:\n",
    "                    w = ''.join(words[idx-1].split('-'))+w\n",
    "                elif idx > 0 and ('stylus' in words[idx-1] or 'miu' in words[idx-1] or 'µ' in words[idx-1] or 'mju' in words[idx-1]):\n",
    "                    w = 'µ'+w\n",
    "#                 if not re.findall(r'^\\d+$', w) or len(w) >= 2:\n",
    "                types.append(w)\n",
    "            elif brand == 'panasonic':\n",
    "#                 print (w)\n",
    "#                 sentence = ''.join(words[0:min(10,len(words))])\n",
    "#                 if idx < len(words)-1 and words[idx+1] in ['rs', 'wp', 'sw', 'ee', 'x']:\n",
    "#                     w = w+words[idx+1]\n",
    "                if idx > 0 and ''.join(words[idx-1].split('-')) in ['dmc', 'f','g','fx','fz','l','ls','lx','lz','ts','tz','zs']:\n",
    "                    w = ''.join(words[idx-1].split('-'))+w\n",
    "#                 if not re.findall(r'^\\d+$', w) or len(w) >= 2:\n",
    "                types.append(w)\n",
    "            elif brand == 'sony':\n",
    "#                 print (w)\n",
    "#                 sentence = ''.join(words[0:min(10,len(words))])\n",
    "                if w == 'effio':\n",
    "                    if words[idx+1] in ['p', 's', 'e', 'v', 'a']:\n",
    "                        w = w+words[idx+1]\n",
    "                if idx > 0 and ''.join(words[idx-1].split('-')) in ['cd','alpha','t','fd','dsc','nex','slt','s','a']:\n",
    "                    w = ''.join(words[idx-1].split('-'))+w\n",
    "                elif idx > 0 and ''.join(words[idx-1].split('-')) in ['alpha', 'ilce', 'ilca']:\n",
    "                    w = 'alpha'+w\n",
    "                if not re.findall(r'^\\d+$', w):\n",
    "                    types.append(w)\n",
    "            else:\n",
    "                if re.findall(r'^\\d+$', w):\n",
    "                    if idx > 0 and words[idx-1] in all_brands:\n",
    "                        types.append(w)\n",
    "                    elif idx > 1 and words[idx-2] in all_brands:\n",
    "                        if not re.findall(r'\\d+', words[idx-1]) and words[idx-1] not in ['camera', 'digital', 'slr', 'series']:\n",
    "                            types.append(words[idx-1] + '-' + w)\n",
    "                    elif idx > 2 and words[idx-3] in all_brands:\n",
    "                        if not re.findall(r'\\d+', words[idx-1]) and words[idx-1] not in ['camera', 'digital', 'slr', 'series']:\n",
    "                            types.append(words[idx-1] + '-' + w)\n",
    "                        if not re.findall(r'\\d+', words[idx-2]) and words[idx-2] not in ['camera', 'digital', 'slr', 'series']:\n",
    "                            types.append(words[idx-2] + '-' + w)\n",
    "                        keep_num += 1\n",
    "                    elif idx > 3 and words[idx-4] in all_brands:\n",
    "                        if not re.findall(r'\\d+', words[idx-1]) and words[idx-1] not in ['camera', 'digital', 'slr', 'series']:\n",
    "                            types.append(words[idx-1] + '-' + w)\n",
    "                        if not re.findall(r'\\d+', words[idx-2]) and words[idx-2] not in ['camera', 'digital', 'slr', 'series']:\n",
    "                            types.append(words[idx-2] + '-' + w)\n",
    "                        if not re.findall(r'\\d+', words[idx-3]) and words[idx-3] not in ['camera', 'digital', 'slr', 'series']:\n",
    "                            types.append(words[idx-3] + '-' + w)\n",
    "                        keep_num += 2\n",
    "                    else:\n",
    "                        types.append(w)\n",
    "                else:\n",
    "                    types.append(w)\n",
    "#             types = list(set(types) - (stopped_words - all_brands))\n",
    "#     print (types)\n",
    "    types = types[0:min(keep_num, len(types))]\n",
    "    if len(types) == 0 and not pd.isnull(row['camera_model']):\n",
    "        models = re.split(r'[;/]', str(row['camera_model']))\n",
    "        mmmmms = [''.join(m.split(' ')) for m in models]\n",
    "#         for m in models:\n",
    "#             if verify_model(m, len(types)):\n",
    "#                 mmmmms.append(m.strip('\"\\''))\n",
    "        models = set(mmmmms) - stopped_words\n",
    "#         models = sorted(re.split(r'[; ]', str(row['camera_model'])), key=lambda x: tfidf(x), reverse=False)\n",
    "#         models = models[0:min(len(models), 2)]\n",
    "        models = sorted(models, key=lambda x: tfidf(x), reverse=False)\n",
    "        if len(models) > 0:\n",
    "            types = set(types) | set(models[0:1])\n",
    "    if len(types) == 0 and not pd.isnull(row['camera_mpn']):\n",
    "        types.append(str(row['camera_mpn']))\n",
    "    types = set([''.join(t.split('-')) for t in types]) - stopped_words\n",
    "    types = sorted(types, key=lambda x: tfidf(x), reverse=False)\n",
    "#     types = types[0:min(len(types), 5)]\n",
    "#     has_number = []\n",
    "#     for i in range(len(types)):\n",
    "#         if re.findall(r'\\d+', types[i]):\n",
    "#             has_number.append(i)\n",
    "#     if len(has_number) > 0:\n",
    "#         typess = []\n",
    "#         for ii in has_number:\n",
    "#             typess.append(types[ii])\n",
    "#         types = typess\n",
    "    types = types[0:min(len(types), keep_num)]\n",
    "    for idx, t in enumerate(types):\n",
    "        if t.endswith('/b'):\n",
    "            types[idx] = types[idx][0:-2]\n",
    "        elif 'rx100' in t and t.endswith('b'):\n",
    "            types[idx] = types[idx][0:-1]\n",
    "        if version is None:\n",
    "            if t.endswith('iii'):\n",
    "                version = '3'\n",
    "#                 types[idx] = types[idx][0:-3]\n",
    "            elif t.endswith('ii'):\n",
    "                version = '2'\n",
    "#                 types[idx] = types[idx][0:-2]\n",
    "            elif t.endswith('m3'):\n",
    "                version = '3'\n",
    "#                 types[idx] = types[idx][0:-2]\n",
    "            elif t.endswith('m2'):\n",
    "                version = '2'\n",
    "#                 types[idx] = types[idx][0:-2]\n",
    "    if version is None:\n",
    "        version = ''\n",
    "    return ';'.join(types), version\n",
    "\n",
    "def extract_type_number(row):\n",
    "    all_types = str(row['type']).split(';')\n",
    "    numbers = []\n",
    "    for t in all_types:\n",
    "        num = re.findall(r'\\d+', str(t))\n",
    "        if len(num) > 0:\n",
    "            numbers.append(''.join(num))\n",
    "    return ';'.join(numbers)\n",
    "\n",
    "def some_extra_rule(row):\n",
    "    mapping = {'600d':'t3i', '1100d':'t3', '550d':'t2i', '500d':'t1i','700d':'t5i', '1000d':'xs', '650d':'t4i',\n",
    "           't3i':'600d', 't3':'1100d', 't2i':'550d', 't1i':'500d','t5i':'700d', 'xs':'1000d', 't4i':'650d',\n",
    "               'xti':'400d','400d':'xti', 'xt':'350d', '350d':'xt', 't5':'1200d', '1200d':'t5',\n",
    "               'xsi':'450d', '450d':'xsi', 'sl1':'100d', '100d':'sl1'}\n",
    "    all_types = str(row['type']).split(';')\n",
    "    added = []\n",
    "    for i in range(len(all_types)):\n",
    "#         if all_types[i] == 'g1' and str(row['blocking_key']) == 'cannon':\n",
    "#             all_types[i] = 'g1x'\n",
    "        if str(row['blocking_key']) == 'nikon':\n",
    "            if 'cool' in str(row['page_title']):\n",
    "                all_types[i] = all_types[i]+'coolpix'\n",
    "        elif str(row['blocking_key']) == 'olympus':\n",
    "            if 'stylus' in all_types[i]:\n",
    "                all_types[i].replace('stylus', 'µ')\n",
    "            elif 'mju' in all_types[i]:\n",
    "                all_types[i].replace('mju', 'µ')\n",
    "        elif all_types[i] in ['7k', '7', 'ilce7', 'ilce7k', 'alpha7', 'alpha7k', 'nex7'] and str(row['blocking_key']) == 'sony':\n",
    "            if 'nex' in row['page_title']:\n",
    "                all_types[i] = 'nex7k'\n",
    "            elif 'ilce' in row['page_title']:\n",
    "                all_types[i] = 'a7k'\n",
    "            elif 'alpha' in row['page_title']:\n",
    "                all_types[i] = 'a7k'\n",
    "        elif all_types[i] in ['a7'] and str(row['blocking_key']) == 'sony':\n",
    "            if 'nex' not in row['page_title']:\n",
    "                all_types[i] = 'a7k'\n",
    "            else:\n",
    "                all_types[i] = 'nex7k'\n",
    "        elif all_types[i] in ['alpha7'] and str(row['blocking_key']) == 'sony':\n",
    "            if 'nex' not in row['page_title']:\n",
    "                all_types[i] = 'a7k'\n",
    "            else:\n",
    "                all_types[i] = 'nex7k'\n",
    "        elif all_types[i] in ['nex7'] and str(row['blocking_key']) == 'sony':\n",
    "            all_types[i] = 'nex7k'\n",
    "        elif all_types[i] == 'nex3':\n",
    "            all_types[i] = 'nex3k'\n",
    "        elif all_types[i] == 'nex5':\n",
    "            all_types[i] = 'nex5k'\n",
    "        elif re.findall(r'\\d+m$', all_types[i]):\n",
    "            all_types[i] = all_types[i][0:-1]\n",
    "        elif 'rx100' in all_types[i]:\n",
    "            if all_types[i].endswith('iii'):\n",
    "                all_types[i] = all_types[i][0:-3]\n",
    "            elif all_types[i].endswith('ii'):\n",
    "                all_types[i] = all_types[i][0:-2]\n",
    "            elif all_types[i].endswith('m3'):\n",
    "                all_types[i] = all_types[i][0:-2]\n",
    "            elif all_types[i].endswith('m2'):\n",
    "                all_types[i] = all_types[i][0:-2]\n",
    "        if str(row['blocking_key']) == 'cannon' and all_types[i] in mapping:\n",
    "            added.append(mapping[all_types[i]])\n",
    "    return ';'.join(all_types+added)\n",
    "\n",
    "def isVersionNeeded(row):\n",
    "    for t in str(row['type']).split(';'):\n",
    "        if row['blocking_key'] == 'cannon':\n",
    "            if (t.startswith('xt')\n",
    "                or t.startswith('xs')\n",
    "                or t.startswith('g1x')\n",
    "                or t.startswith('5d')\n",
    "                or t.startswith('1d')\n",
    "                or t.startswith('7d')\n",
    "                or t.startswith('t3')\n",
    "                or t.startswith('t5')\n",
    "                or t.startswith('t1')\n",
    "                or t.startswith('t2')\n",
    "                or t.startswith('t4')):\n",
    "                return 1\n",
    "        elif row['blocking_key'] == 'sony':\n",
    "            if ('rx1' in t\n",
    "                or t.startswith('a77')):\n",
    "                return 1\n",
    "        elif row['blocking_key'] == 'nikon':\n",
    "            return 1\n",
    "        elif row['blocking_key'] == 'fuji':\n",
    "            if t.startswith('x100'):\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def may_similar_type(df):\n",
    "    cofreqs = {}\n",
    "    singlefreqs = {}\n",
    "    total = 0\n",
    "    for x in df['type'].values:\n",
    "        v = str(x).split(';')\n",
    "        for vv in v:\n",
    "            if vv in singlefreqs:\n",
    "                singlefreqs[vv] += 1\n",
    "            else:\n",
    "                singlefreqs[vv] = 1\n",
    "            total += 1\n",
    "        for i in range(len(v)):\n",
    "            for j in range(i+1,len(v)):\n",
    "                if v[i] >= v[j]:\n",
    "                    pair = (v[j],v[i])\n",
    "                else:\n",
    "                    pair = (v[i],v[j])\n",
    "                if pair in cofreqs:\n",
    "                    cofreqs[pair] += 1\n",
    "                else:\n",
    "                    cofreqs[pair] = 1\n",
    "#         for pair in cofreqs.keys():\n",
    "#             cofreqs[pair] = cofreqs[pair] / float(singlefreqs[pair[0]] * singlefreqs[pair[1]])\n",
    "    return cofreqs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361f70de4f2a406783ce44c3143fece6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=29787.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d1e3643ca74479bf606e3da8e75abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=29787.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecfc8e047df4524ae6ddc0e2748163f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=29787.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c1632d208e47989b37bdf879f945ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=29787.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import swifter\n",
    "structured_data['type'], structured_data['version'] = zip(*structured_data.swifter.apply(lambda row: extract_type(row), axis=1))\n",
    "structured_data['type'] = structured_data.swifter.apply(lambda row: some_extra_rule(row), axis=1)\n",
    "structured_data['type_number'] = structured_data.swifter.apply(lambda row: extract_type_number(row), axis=1)\n",
    "structured_data['need_version'] = structured_data.swifter.apply(lambda row: isVersionNeeded(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dschx50v', '')\n",
      "page_title      sony cyber-shot dsc-hx50v digital camera, 20.4...\n",
      "camera_brand                                                  NaN\n",
      "camera_model                                        0002724286222\n",
      "camera_mpn                                                    NaN\n",
      "blocking_key                                                 sony\n",
      "type                                                     dschx50v\n",
      "version                                                          \n",
      "type_number                                                    50\n",
      "Name: www.buzzillions.com//2484, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wb350'"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(extract_type(structured_data.loc['www.buzzillions.com//2484']))\n",
    "print (structured_data.loc['www.buzzillions.com//2484'])\n",
    "s = 'wb350.'\n",
    "s = s.strip(',;-().\"\\'')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nikon coolpix a black 16.2mp f2.8 3\" 1080p 32009'"
      ]
     },
     "execution_count": 1136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(extract_type(structured_data.loc['www.henrys.com//215']))\n",
    "structured_data.loc['www.henrys.com//215']['page_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "structured_data = structured_data.fillna('')\n",
    "structured_data[structured_data['blocking_key']==''].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_type(structured_data.loc['www.ebay.com//58630']))\n",
    "structured_data.loc['www.ebay.com//58630']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "structured_data.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data.loc['www.alibaba.com//30151']['page_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data.loc['www.ebay.com//43237']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data.to_csv('total_with_key_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "structured_data['type'] = structured_data['type'].fillna('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data = structured_data.fillna('')\n",
    "len(structured_data[structured_data['page_title'].str.contains('lexar')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import swifter\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask.multiprocessing import get\n",
    "import editdistance\n",
    "\n",
    "# stopped_words = set(['digital camera', 'digital', 'camera'])\n",
    "ddata = dd.from_pandas(candidate_pairs, npartitions=2*multiprocessing.cpu_count())\n",
    "# ddata = dd.from_pandas(candidate_pairs[0:4], npartitions=2)\n",
    "def apply_df(df):\n",
    "#     structured_data = pd.read_csv('total_normalized.csv').set_index('camera_ids')\n",
    "    print (len(df))\n",
    "    return df.apply(lambda row: decide_keep(row, structured_data), axis=1)\n",
    "\n",
    "def decide_keep(row, structured_data):\n",
    "    stopped_words = set(['digital camera', 'camera']) | all_brands\n",
    "\n",
    "    llll = structured_data.loc[row['left_spec_id']]\n",
    "    rrrr = structured_data.loc[row['right_spec_id']]\n",
    "\n",
    "    lset = set(str(llll['type']).split(';'))\n",
    "    rset = set(str(rrrr['type']).split(';'))\n",
    "\n",
    "    max_len = max(len(str(llll['type'])), len(str(rrrr['type'])))\n",
    "    camera_type_edit_dis=(editdistance.eval(''.join(sorted(lset)), ''.join(sorted(rset))) / float(max_len))\n",
    "\n",
    "    if len(lset) == 0 and len(rset) == 0:\n",
    "        camera_type_jaccard_dis=(0.0)\n",
    "        camera_type_overlap_dis=(0.0)\n",
    "    else:\n",
    "        camera_type_jaccard_dis=(1.0 - len(lset&rset) / float(len(lset|rset)))\n",
    "        camera_type_overlap_dis=(1.0 - len(lset&rset) / float(max(len(lset), len(rset))))\n",
    "\n",
    "    lset = set(re.findall(r\"\\d+\\.?\\d*\",str(llll['type'])))\n",
    "    rset = set(re.findall(r\"\\d+\\.?\\d*\",str(rrrr['type'])))\n",
    "\n",
    "    if len(lset) == 0 and len(rset) == 0:\n",
    "        camera_type_numeric_jaccard_dis=(0.0)\n",
    "        camera_type_numeric_overlap_dis=(0.0)\n",
    "    else:\n",
    "        camera_type_numeric_jaccard_dis=(1-len(lset&rset) / float(len(lset|rset)))\n",
    "        camera_type_numeric_overlap_dis=(1.0 - len(lset&rset) / float(max(len(lset), len(rset))))\n",
    "\n",
    "    lnumtitle = re.findall(r\"\\d+\",str(llll['page_title']))\n",
    "    rnumtitle = re.findall(r\"\\d+\",str(rrrr['page_title']))\n",
    "\n",
    "    lset = set(lnumtitle)\n",
    "    rset = set(rnumtitle)\n",
    "\n",
    "    if len(lset) == 0 and len(rset) == 0:\n",
    "        camera_title_numeric_jaccard_dis=(0.0)\n",
    "        camera_title_numeric_edit_dis=(0.0)\n",
    "    else:\n",
    "        camera_title_numeric_jaccard_dis=(1.0 - len(lset&rset) / float(len(lset|rset)))\n",
    "        max_len = max(len(lnumtitle), len(rnumtitle))\n",
    "        camera_title_numeric_edit_dis=(editdistance.eval(lnumtitle, rnumtitle) / float(max_len))\n",
    "\n",
    "    ltitle = str(llll['page_title']).split(' ')\n",
    "    rtitle = str(rrrr['page_title']).split(' ')\n",
    "    lset = set(ltitle)\n",
    "    rset = set(rtitle)\n",
    "\n",
    "    if len(lset) == 0 and len(rset) == 0:\n",
    "        camera_title_jaccard_dis=(0.0)\n",
    "        camera_title_overlap_dis=(0.0)\n",
    "        camera_title_edit_dis=(0.0)\n",
    "    else:\n",
    "        camera_title_jaccard_dis=(1.0-len(lset&rset) / float(len(lset|rset)))\n",
    "        camera_title_overlap_dis=(1.0 - len(lset&rset) / float(max(len(lset), len(rset))))\n",
    "        max_len = max(len(ltitle), len(rtitle))\n",
    "        camera_title_edit_dis=(editdistance.eval(ltitle, rtitle) / float(max_len))\n",
    "    overlap_freqs = []\n",
    "    for w in lset&rset:\n",
    "        if w in word_tfidf:\n",
    "            overlap_freqs.append(str(word_tfidf[w]))\n",
    "    camera_title_overlap_freq=(';'.join(overlap_freqs))\n",
    "    unmatch_freqs = []\n",
    "    for w in (lset|rset)-(lset&rset):\n",
    "        if w in word_tfidf:\n",
    "            unmatch_freqs.append(str(word_tfidf[w]))\n",
    "    camera_title_unmatch_freq=(';'.join(unmatch_freqs))\n",
    "        \n",
    "    return [camera_type_jaccard_dis, camera_type_overlap_dis,\n",
    "            camera_type_edit_dis, camera_type_numeric_jaccard_dis,\n",
    "            camera_type_numeric_overlap_dis,camera_title_jaccard_dis,\n",
    "            camera_title_overlap_dis,camera_title_edit_dis,\n",
    "            camera_title_numeric_jaccard_dis,camera_title_numeric_edit_dis,\n",
    "            camera_title_overlap_freq,camera_title_unmatch_freq]\n",
    "\n",
    "print ('begin')\n",
    "# column = {'camera_type_jaccard_dis':float,'camera_type_numeric_jaccard_dis':float,'camera_title_jaccard_dis':float,'camera_type_overlap_dis':float,'camera_type_numeric_overlap_dis':float,'camera_title_overlap_dis':float,'camera_title_overlap_freq':str}\n",
    "# res = ddata.apply(lambda row: decide_keep(row, structured_data), axis=1, meta=pd.Series(dtype=float,name='x')).compute(scheduler='processes')\n",
    "res = ddata.map_partitions(lambda df: apply_df(df), meta=pd.Series(name='x')).compute(scheduler='processes') \n",
    "# candidate_pairs['keep'] = candidate_pairs.swifter.apply(lambda row: decide_keep(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df['camera_type_jaccard_dis'] = camera_type_jaccard_dis\n",
    "    pairs_df['camera_type_overlap_dis'] = camera_type_overlap_dis\n",
    "    pairs_df['camera_type_edit_dis'] = camera_type_edit_dis\n",
    "    pairs_df['camera_type_numeric_jaccard_dis'] = camera_type_numeric_jaccard_dis\n",
    "    pairs_df['camera_type_numeric_overlap_dis'] = camera_type_numeric_overlap_dis\n",
    "    pairs_df['camera_title_jaccard_dis'] = camera_title_jaccard_dis\n",
    "    pairs_df['camera_title_overlap_dis'] = camera_title_overlap_dis\n",
    "    pairs_df['camera_title_edit_dis'] = camera_title_edit_dis\n",
    "    pairs_df['camera_title_numeric_jaccard_dis'] = camera_title_numeric_jaccard_dis\n",
    "    pairs_df['camera_title_numeric_edit_dis'] = camera_title_numeric_edit_dis\n",
    "    pairs_df['camera_title_overlap_freq'] = camera_title_overlap_freq\n",
    "    pairs_df['camera_title_unmatch_freq'] = camera_title_unmatch_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "candidate_pairs['camera_type_jaccard_dis'] = [x[0] for x in res]\n",
    "candidate_pairs['camera_type_overlap_dis'] = [x[1] for x in res]\n",
    "candidate_pairs['camera_type_edit_dis'] = [x[2] for x in res]\n",
    "candidate_pairs['camera_type_numeric_jaccard_dis'] = [x[3] for x in res]\n",
    "candidate_pairs['camera_type_numeric_overlap_dis'] = [x[4] for x in res]\n",
    "candidate_pairs['camera_title_jaccard_dis'] = [x[5] for x in res]\n",
    "candidate_pairs['camera_title_overlap_dis'] = [x[6] for x in res]\n",
    "candidate_pairs['camera_title_edit_dis'] = [x[7] for x in res]\n",
    "candidate_pairs['camera_title_numeric_jaccard_dis'] = [x[8] for x in res]\n",
    "candidate_pairs['camera_title_numeric_edit_dis'] = [x[9] for x in res]\n",
    "candidate_pairs['camera_title_overlap_freq'] = [x[10] for x in res]\n",
    "candidate_pairs['camera_title_unmatch_freq'] = [x[11] for x in res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidate_pairs.loc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs.to_csv('candidates_with_distance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs = pd.read_csv('candidates_with_distance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs['keep'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs[candidate_pairs['keep'] == 1].to_csv('candidates_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs['camera_title_overlap_freq'] = candidate_pairs['camera_title_overlap_freq'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# distances_data = list(candidate_pairs.iloc[:, 4:12].values)\n",
    "# # freqs_data = list(candidate_pairs.iloc[:, 11:12].values)\n",
    "# others_data = list(candidate_pairs.iloc[:, 4:5].values)\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(\n",
    "#         ProductsDataset(distances_data, others_data), batch_size=1024, shuffle=False)\n",
    "\n",
    "# distances_model.eval()\n",
    "# freqs_model.eval()\n",
    "output_model.eval()\n",
    "results = []\n",
    "matches = 0\n",
    "start = time.time()\n",
    "for batch_idx, (distances, targets) in enumerate(data_loader):\n",
    "    distance = Variable(distances)\n",
    "#     target = Variable(targets)\n",
    "    freq = Variable(freqs)\n",
    "\n",
    "#     distance_embedding = distances_model(distance) \n",
    "#     freq_embedding = freqs_model(freq)\n",
    "    estimates = output_model(distance)\n",
    "    \n",
    "    for i in range(estimates.shape[0]):\n",
    "        if estimates[i].item() >= 0.5:\n",
    "            results.append(1)\n",
    "            matches += 1\n",
    "        else:\n",
    "            results.append(0)\n",
    "            \n",
    "    end = time.time()\n",
    "    print ('Testing: Iteration {}, Time: {}s, MatchNum: {}, CurrentNum: {}'.format(e, end-start, matches, len(results)))\n",
    "    start = time.time()\n",
    "# print ('Testing: Iteration {}'.format(e, np.mean(mse_errors), np.mean(precisions), np.mean(recalls)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs['predict'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs[candidate_pairs['predict'] == 1][['left_spec_id', 'right_spec_id']].to_csv('submit_v7.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs[candidate_pairs['predict'] == 1].to_csv('candidates_positive_with_distance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candidate_pairs[candidate_pairs['predict'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
